{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de3eddd",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "Installs necessary requirements and configures proper notebook behavior  \n",
    "Note: The notebook assumes you are using the base conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c506dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook setup has completed\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "print(\"Notebook setup has completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b600f8",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Downloads configured dataset and performs necessary environment bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61fb28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup has completed\n"
     ]
    }
   ],
   "source": [
    "from bootstrap import setup\n",
    "\n",
    "\n",
    "# Please rename .env-template to .env and adjust values as needed\n",
    "setup()\n",
    "\n",
    "print(\"Environment setup has completed\")\n",
    "\n",
    "del setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc59bc",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "Available data split into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "047a2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_dataframe, get_subsets_no_val\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "df = get_dataframe()  # In the form [features, labels]\n",
    "\n",
    "word_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    analyzer=\"word\", \n",
    "    min_df=0.001, \n",
    "    max_df=0.7\n",
    "    )\n",
    "X = df[\"review\"].to_numpy()\n",
    "X = word_vectorizer.fit_transform(X)\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).to_numpy()\n",
    "\n",
    "# TODO: Transform raw text into a representation suitable for a MLP\n",
    "# df can has as many feature columns as needed, but the last column must be the label column\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_subsets_no_val(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11c14f",
   "metadata": {},
   "source": [
    "# Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fafbfaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and shapes:\n",
      "X_train: <class 'scipy.sparse._csr.csr_matrix'> of shape (40000, 33418)\n",
      "Y_train: <class 'numpy.ndarray'> of shape (40000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data and shapes:\")\n",
    "print(\"X_train:\", type(X_train), \"of shape\", X_train.shape)\n",
    "print(\"Y_train:\", type(y_train), \"of shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a7423632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [15:32<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from mlp import MultiLayerPerceptron\n",
    "from analysis import accuracy\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "mlp = MultiLayerPerceptron(\n",
    "    epochs=150,\n",
    "    lr=0.05,\n",
    "    input_layer=input_size,\n",
    "    hidden_layers=[30, 10],\n",
    "    output_layer=1,\n",
    "    activation=\"sigmoid\",\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6a29b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(mlp.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b03803e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9096, 0.9101, 0.9123, 0.9111, 0.9086, 0.911, 0.9091, 0.9147, 0.9124, 0.9123, 0.9119, 0.9102, 0.9092, 0.913, 0.9111] : 0.9111066666666666\n",
      "7 is the best classifier\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from multip import train_mlp\n",
    "import numpy as np\n",
    "\n",
    "PROCCESSES = cpu_count() - 1\n",
    "classifiers = []\n",
    "with Pool(PROCCESSES) as p:\n",
    "    classifiers = p.map(train_mlp, [(X_train, y_train, X_test, y_test)] * PROCCESSES)\n",
    "accuracies = [clf.score(X_test, y_test) for clf in classifiers]\n",
    "print(accuracies, \":\", np.mean(accuracies))\n",
    "print(np.argmax(accuracies), \"is the best classifier\")\n",
    "best_clf = classifiers[np.argmax(accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1d1624a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive example is 6197\n",
      "Most negative example is 8165\n",
      "Most neutral example is 5622\n",
      "Most incorrect example is 2694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = best_clf.predict_proba(X_test)\n",
    "p = p @ np.array([-1,1]).reshape(2,1)\n",
    "print(f\"Most positive example is {np.argmax(p)}\")\n",
    "print(f\"Most negative example is {np.argmin(p)}\")\n",
    "print(f\"Most neutral example is {np.argmin(np.abs(p))}\")\n",
    "\n",
    "p = (p*0.5 + 0.5)\n",
    "incorrect_amount = p - y_test.reshape(-1,1)\n",
    "print(f'Most incorrect example is {np.argmax(np.abs(incorrect_amount))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5f119f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 [1.]\n",
      "Actual: 1\n",
      "['one' 'has' 'just' 'you' 'be' 'are' 'right' 'as' 'what' 'with' 'br'\n",
      " 'violence' 'which' 'from' 'go' 'not' 'or' 'no' 'on' 'city' 'an' 'where'\n",
      " 'all' 'have' 'so' 'more' 'far' 'fact' 'audiences' 'around' 'ever' 'who'\n",
      " 'out' 'get' 'well' 'middle' 'into' 'experience' 'if' 'can' 'side'\n",
      " 'one of' 'of the' 'this is' 'br br' 'br the' 'from the' 'in the' 'it is'\n",
      " 'as that' 'that is' 'is the' 'to the' 'all the' 'on the' 'more so'\n",
      " 'that it' 'out for' 'and get' 'with it' 'what is' 'you can' 'very' 'time'\n",
      " 'sense' 'realism' 'only' 'he' 'down' 'pat' 'see' 'by' 'written' 'his'\n",
      " 'life' 'things' 'rather' 'than' 'sets' 'done' 'sense of' 'of realism'\n",
      " 'not only' 'by the' 'but it' 'written and' 'rather than' 'and the' 'way'\n",
      " 'dialogue' 'characters' 'even' 'serial' 'killer' 'while' 'some' 'style'\n",
      " 'us' 'most' 'at' 'years' 'been' 'she' 'her' 'young' 'woman' 'interesting'\n",
      " 'the dialogue' 'dialogue is' 'the characters' 'characters are'\n",
      " 'serial killer' 'of us' 'the most' 'in this' 'young woman' 'of his'\n",
      " 'there' 'make' 'film' 'drama' 'we' '10' 'in his' 'with his' 'the film'\n",
      " 'to see' 'play' 'director' 'action' 'these' 'another' 'world' 'own'\n",
      " 'gets' 'picture' 'big' 'best' 'case' 'good' 'talented' 'cast' 'come'\n",
      " 'work' 'to be' 'the director' 'the action' 'or another' 'we are'\n",
      " 'the picture' 'big city' 'the best' 'my' 'story' 'having' 'last' 'paul'\n",
      " 'performance' 'roles' 'up' 'makes' 'believable' 'had' 'the last' 'of her'\n",
      " 'but that' 'is believable' 'believable and' 'for this' 'sure' 'series'\n",
      " 'today' 'bring' 'back' 'pace' 'any' 'up on' 'and this' 'bad'\n",
      " 'performances' 'hard' 'original' 'also' 'fit' 'made' 'and it'\n",
      " 'the original' 'that made' 'as it' 'here' 'films' 'country' 'played'\n",
      " 'end' 'least' 'and is' 'the end' 'is far' 'at least' 'gut' 'low' 'itself'\n",
      " 'something' 'better' 'is one' 'as the' 'beautiful' 'care' 'much' 'year'\n",
      " 'psycho' 'since' 'br as' 'the story' 'again' 'long' 'before' 'actually'\n",
      " 'however' 'true' 'beyond' 'evil' 'top' 'take' 'ahead' 'him' 'screen'\n",
      " 'to play' 'played by' 'go ahead' 'who makes' 'because' 'keep' 'does'\n",
      " 'cut' 'to bring' 'br in' 'to keep' 'kind' 'drawn' 'town' 'nonsense'\n",
      " 'encounters' 'kind of' 'with all' 'in that' 'this one' 'exception'\n",
      " 'character' 'and of' 'as he' 'the character' 'character of' 'film in'\n",
      " 'beginning' 'both' 'wait' 'someone' 'with one' 'if it' 'cinema' 'anyone'\n",
      " 'the cinema' 'perfectly' 'artist' 'enough' 'guy' 'undeniably' 'burning'\n",
      " 'actually very' 'best of' 'can be' 'to her' 'bad guy' 'aspects'\n",
      " 'that make' 'all of' 'carries' 'matter' 'sudden' 'worse' 'over' 'tape'\n",
      " 'in fact' 'to take' 'part' 'who can' 'though' 'role' 'the role' 'genre'\n",
      " 'jennifer' 'wants' 'reality' 'audience' 'whoever' 'is an' 'at work'\n",
      " 'into the' 'wants to' 'what it' 'picture br' 'once' 'spirit' 'behind'\n",
      " 'end br' 'able' 'stand' 'america' 'typical' 'able to' 'conflict'\n",
      " 'starring' 'law' 'entirely' 'dirty' 'puts' 'becomes' 'north' 'course'\n",
      " 'helps' 'brought' 'upon' 'within' 'two' 'ray' 'greatly' 'effective'\n",
      " 'tactics' 'manages' 'justice' 'between' 'unique' 'lives' 'that has'\n",
      " 'done and' 'not so' 'the audience' 'something of' 'have brought'\n",
      " 'manages to' 'distinctive' 'police' 'second' 'draws' 'small' 'murder'\n",
      " 'works' 'question' 'the second' 'and as' 'her life' 'in small' 'directed'\n",
      " 'successful' 'creates' 'approach' 'himself' 'satisfaction' 'portraying'\n",
      " 'through' 'directed by' 'his own' 'him to' 'he is' 'part of' 'the films'\n",
      " 'ultimately' 'gradually' 'without' 'deliberate' 'impossible' 'provide'\n",
      " 'behind the' 'between the' 'since the' 'impossible to' 'film that'\n",
      " 'tension' 'gave' 'it interesting' 'because of' 'purely' 'or at' 'is in'\n",
      " 'no matter' 'to this' 'the serial' 'front' 'one to' 'just as' 'but at'\n",
      " 'of course' 'in front' 'front of' 'have him' 'him in' 'has made' 'camera'\n",
      " 'her character' 'the camera' 'hold' 'james' 'it had' 'personal'\n",
      " 'continuity' 'local' 'held' 'one the' 'events' 'level' 'working'\n",
      " 'and that' 'as well' 'well as' 'whose' 'supporting' 'through the' 'stuff'\n",
      " 'anyone who' 'screenplay' 'charles' 'spencer' 'sees' 'benefits'\n",
      " 'she sees' 'his way' 'and he' 'he does' 'to end' 'so he' 'counterpart'\n",
      " 'clint' 'eastwood' 'credibility' 'methods' 'impact' 'clint eastwood'\n",
      " 'is where' 'ended' 'found' 'day' 'seeing' 'heart' 'ended up' 'the law'\n",
      " 'in seeing' 'the screen' 'mark' 'settled' 'from there' 'includes'\n",
      " 'necessary' 'often' 'knowing' 'elements' 'perfect' 'popular' 'form'\n",
      " 'criminals' 'engaging' 'knowing the' 'albert' 'stage' 'convincing' 'five'\n",
      " 'upon the' 'that of' 'from beginning' 'beginning to' 'and talented'\n",
      " 'all but' 'and becomes' 'interesting and' 'moral' 'in supporting'\n",
      " 'supporting roles' 'investigation' 'material' 'definitely' 'small town'\n",
      " 'beautiful and' 'is well' 'well written' 'presence' 'that makes' 'brand'\n",
      " 'philosophy' 'harry' 'focus' 'within the' 'makes for' 'bond' 'bar'\n",
      " 'james bond' 'the perfect' 'it even' 'even if' 'finds' 'her to'\n",
      " 'the violence' 'keeps' 'elsewhere' 'the very' 'of one' 'as she' 'limited'\n",
      " 'the unique' 'traumatic' 'discovers' 'of and' 'quickly' 'the screenplay'\n",
      " 'from reality' 'is typical' 'convincing and' 'the guy' 'the local'\n",
      " 'it only' 'way which' 'from seeing' 'him for' 'the middle' 'course this'\n",
      " 'possibly' 'red' 'the burning' 'the red' 'screen time' 'involving'\n",
      " 'not one' 'screen and' 'individual' 'side of' 'sean' 'connery'\n",
      " 'sean connery' 'vacation' 'the five' 'much to' 'chair' 'involves'\n",
      " 'in any' 'cinematic' 'the things' 'things that' 'the bad' 'victims'\n",
      " 'the victims' 'which he' 'us that' 'parallels' 'department' 'that have'\n",
      " 'ordered' 'made of' 'come from' 'middle of' 'smith' 'had been'\n",
      " 'cinema and' 'typical of' 'of in' 'andy' 'joseph' 'or as' 'adds'\n",
      " 'make this' 'once again' 'steps' 'is he' 'fascination' 'this character'\n",
      " 'character with' 'elements that' 'catch' 'role of' 'killer in' 'offering'\n",
      " 'genuinely' 'satisfying' 'it impossible' 'gap' 'bennett' 'material and'\n",
      " 'here in' 'who we' 'we all' '1976' 'portrayal' 'portrayal of' 'blend'\n",
      " 'down in' 'gave us' 'that all' 'vigilante' 'fourth' 'the fourth'\n",
      " 'found in' 'recent' 'camera and' 'to that' 'and out' 'determination'\n",
      " 'swift' 'than ever' 'wait to' 'the series' 'the elements' 'vengeance'\n",
      " 'freedom' 'ever been' 'this country' 'though is' 'are well' 'is able'\n",
      " 'aspects of' 'successful in' 'code' 'world that' 'supporting cast' 'link'\n",
      " 'proverbial' 'both in' 'dear' 'and action' 'on with' 'it by' 'can wait'\n",
      " 'the kind' 'day br' 'establishing' 'focus on' 'of stuff' 'robinson' 'mrs'\n",
      " 'continues' 'essence' 'take care' 'care of' 'and made' 'directs'\n",
      " 'made the' 'these films' 'keep it' 'seven' 'seven years' 'edged'\n",
      " 'very limited' 'and works' 'years since' 'character but' 'response'\n",
      " 'films so' 'is entirely' 'definitely not' 'essence of' 'smith is'\n",
      " 'performance that' 'as with' 'the supporting' 'cast includes' 'where we'\n",
      " 'least have' 'resistance' 'that works' 'san' 'francisco' 'epitome'\n",
      " 'san francisco' 'the epitome' 'epitome of' 'pierce' 'back into'\n",
      " 'that wants' 'superiors' 'of justice' 'drama and' 'arguably' 'take his'\n",
      " 'inspector' 'the essence' 'take some' 'carrying' 'get on' 'she manages'\n",
      " 'sherlock' 'holmes' 'sherlock holmes' 'conceived' 'for better'\n",
      " 'reality the' 'earl' 'be found' 'snappy' 'screenplay by' 'fit into'\n",
      " 'murder in' 'stand out' 'nancy' 'dynamic' 'brand of' 'successfully'\n",
      " 'links' 'does it' 'vulnerability' 'evil and' 'chief' 'gets his' 'icon'\n",
      " 'of not' 'makes her' 'him around' 'of freedom' 'homicide' 'far beyond'\n",
      " 'only on' 'films he' 'is arguably' 'just enough' 'amid' 'employed'\n",
      " 'better or' 'or worse' 'it helps' 'the drama' 'and starring'\n",
      " 'from having' 'story itself' 'at heart' 'drake' 'laced' 'arguably the'\n",
      " 'he lives' 'dirty harry' 'country and' 'blend of' 'for and' 'so popular'\n",
      " 'evokes' 'freedom and' 'style the' 'establishes' 'who ever' 'anyone but'\n",
      " 'events that' 'time so' 'of drama' 'it what' 'derived' 'derived from'\n",
      " 'we come' 'her portrayal' 'territory' 'finds himself' 'in top' 'pursuing'\n",
      " 'mick' 'deed' 'triumphs' 'the criminals' 'smack' 'character so'\n",
      " 'which adds' 'that gave' 'an individual' 'his big' 'tape and'\n",
      " 'action the' 'facility' 'police chief' 'it adds' 'by and' 'in san'\n",
      " 'only his' 'visceral' 'phrases' 'rathbone' 'and convincing' 'basil'\n",
      " 'pioneers' 'fulfilling' 'and quickly' 'locke' 'has long']\n"
     ]
    }
   ],
   "source": [
    "example = 6197\n",
    "print(f\"Predicted: {best_clf.predict(X_test[example])[0]} {p[example]}\\nActual: {y_test[example]}\")\n",
    "print(word_vectorizer.inverse_transform(X_test[example])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f74f92",
   "metadata": {},
   "source": [
    "## Runs\n",
    "1. 89.98: (10,5), Logisitic, Early Stopping\n",
    "2. 89.95: (10,5), Relu, Early Stopping,\n",
    "3. 89.71: (5), Relu, Early Stopping\n",
    "4. 85.12: (5), Relu, \n",
    "5. 91.11: (5), Relu, Early Stopping, 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acac3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from analysis import accuracy\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(5),\n",
    "    # early_stopping=True,\n",
    ")\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e634ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {accuracy(clf.predict(X_train), y_train)}\")\n",
    "print(f\"Testing accuracy: {accuracy(clf.predict(X_test), y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08a055",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Lambda, Symbol\n",
    "from training import matrix_train\n",
    "\n",
    "\n",
    "x = Symbol(\"x\")\n",
    "\n",
    "\n",
    "# each axis must be an iterable. if you want to use a constant, wrap it in an iterable of len 1\n",
    "hyperparameter_matrix = {\n",
    "    \"epochs\": np.logspace(np.log10(100), np.log10(100000), num=20, dtype=\"int64\"),\n",
    "    \"lr\": np.logspace(np.log10(.00001), np.log10(.1), num=20),\n",
    "    \"hidden_layers\": [5, 6, 7],\n",
    "    \"neurons_per_layer\": [3],\n",
    "    \"activation\": [Lambda(x, x**2)],\n",
    "}\n",
    "\n",
    "best_params = matrix_train(hyperparameter_matrix, MultiLayerPerceptron, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(best_params)\n",
    "# mlp = MultiLayerPerceptron(**best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67082690",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ef1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import accuracy, confusion, report\n",
    "\n",
    "\n",
    "mlp = MultiLayerPerceptron(**best_params)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# print(accuracy(mlp.predict(X_test), y_test))\n",
    "# print(confusion(mlp.predict(X_test), y_test))\n",
    "print(report(mlp.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7f405",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO utilize other classifiers and compare performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaf02dffba55afcb757f8661e47ea199414fefb6fedafc1622a26ab926d7da3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
