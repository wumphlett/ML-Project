{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de3eddd",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "Installs necessary requirements and configures proper notebook behavior  \n",
    "Note: The notebook assumes you are using the base conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "print(\"Notebook setup has completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b600f8",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Downloads configured dataset and performs necessary environment bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import setup\n",
    "\n",
    "\n",
    "# Please rename .env-template to .env and adjust values as needed\n",
    "setup()\n",
    "\n",
    "print(\"Environment setup has completed\")\n",
    "\n",
    "del setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc59bc",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "Available data split into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infrastructure import get_dataframe, get_subsets\n",
    "\n",
    "\n",
    "df = get_dataframe()  # In the form [features, labels]\n",
    "\n",
    "# TODO: Transform raw text into a representation suitable for a MLP\n",
    "# df can has as many feature columns as needed, but the last column must be the label column\n",
    "\n",
    "X_train, X_test, X_validate, y_train, y_test, y_validate = get_subsets(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd30b7f",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Iterable, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        lr: Union[float, Callable[int, float]],\n",
    "        hidden_layers: int,\n",
    "        neurons_per_layer: int,\n",
    "        activation: Union[Callable, Iterable[Callable]]\n",
    "    ):\n",
    "        if isinstance(activation, Iterable):\n",
    "            assert len(activation) == hidden_layers\n",
    "        \n",
    "        self.num_epochs = epochs\n",
    "        self.lr = (lambda x: lr) if isinstance(lr, float) else lr\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.neurons_per_layer = neurons_per_layer\n",
    "        self.activation = activation\n",
    "    \n",
    "    def epochs(self):\n",
    "        for i in range(self.num_epochs):\n",
    "            yield i, self.lr(i)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \n",
    "        for epoch_num, lr in self.epochs():\n",
    "            pass\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08a055",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Lambda, Symbol\n",
    "from training import matrix_train\n",
    "\n",
    "\n",
    "x = Symbol(\"x\")\n",
    "\n",
    "\n",
    "# each axis must be an iterable. if you want to use a constant, wrap it in an iterable of len 1\n",
    "hyperparameter_matrix = {\n",
    "    \"epochs\": np.logspace(np.log10(100), np.log10(100000), num=20, dtype=\"int64\"),\n",
    "    \"lr\": np.logspace(np.log10(.00001), np.log10(.1), num=20),\n",
    "    \"hidden_layers\": [5, 6, 7],\n",
    "    \"neurons_per_layer\": [3],\n",
    "    \"activation\": [Lambda(x, x**2)],\n",
    "}\n",
    "\n",
    "best_params = matrix_train(hyperparameter_matrix, MultiLayerPerceptron, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(best_params)\n",
    "# mlp = MultiLayerPerceptron(**best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67082690",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ef1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import accuracy, confusion, report\n",
    "\n",
    "\n",
    "mlp = MultiLayerPerceptron(**best_params)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# print(accuracy(mlp.predict(X_test), y_test))\n",
    "# print(confusion(mlp.predict(X_test), y_test))\n",
    "print(report(mlp.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7f405",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO utilize other classifiers and compare performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
