{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de3eddd",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "Installs necessary requirements and configures proper notebook behavior  \n",
    "Note: The notebook assumes you are using the base conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# !python -m pip install -r requirements.txt\n",
    "    \n",
    "print(\"Notebook setup has completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24094f",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "Specify which datasets to use and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bootstrap import download_data_file\n",
    "from preprocessing import  CDS_AND_VINYL_JSON_PARAMS, CELL_PHONE_JSON_PARAMS, ELECTRONICS_JSON_PARAMS\n",
    "# DATASETS = [ CDS_AND_VINYL_JSON_PARAMS, CELL_PHONE_JSON_PARAMS, ELECTRONICS_JSON_PARAMS]\n",
    "DATASETS = [ ELECTRONICS_JSON_PARAMS]\n",
    "\n",
    "\n",
    "URL_SOURCE = \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/\"\n",
    "for dataset in DATASETS:\n",
    "    download_data_file(URL_SOURCE, dataset['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b600f8",
   "metadata": {},
   "source": [
    "# Load Data Into Memory\n",
    "Load the data from the gzipped json file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_dataframe_file\n",
    "import pandas as pd\n",
    "POINTS_PER_FILE = 50_000\n",
    "frames = []\n",
    "for dataset in DATASETS:\n",
    "    frame = get_dataframe_file(params = dataset, points=POINTS_PER_FILE, equalize=True)\n",
    "    frame.dropna(inplace=True)\n",
    "    frames.append(frame)\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc59bc",
   "metadata": {},
   "source": [
    "# Format Data\n",
    "Split into training, testing, and validation sets, and transform text into a format that can be used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocessing import get_subsets\n",
    "\n",
    "word_vectorizer = CountVectorizer(\n",
    "    min_df=0.0001, \n",
    "    max_df=0.7\n",
    " )\n",
    "X = df[\"reviewText\"].to_numpy()\n",
    "X = word_vectorizer.fit_transform(X)\n",
    "y = df['overall'].to_numpy()\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_subsets(X,y, train_split=0.8, val_split=0.1, test_split=0.1)\n",
    "print(f\"X_train: {X_train.shape}\\t y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\\t y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\\t y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370a703",
   "metadata": {},
   "source": [
    "# Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "categories, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(categories, counts)\n",
    "plt.title(\"Labels in training set\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "print(\"Label mean: \", np.mean(y_train))\n",
    "print(\"Label Standard Deviation: \", np.std(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11c14f",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MultiLayerPerceptron\n",
    "our_mlp = MultiLayerPerceptron(\n",
    "    epochs=100,\n",
    "    lr=0.2,\n",
    "    hidden_layers=[50, 20],\n",
    "    activation=\"logistic\",\n",
    "    regularization=\"L2\",\n",
    "    reg_const=0.0001,\n",
    ")\n",
    "our_mlp.fit(X_train, y_train, X_val, y_val, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e634ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = our_mlp.score(X_train, y_train)\n",
    "validation_score = our_mlp.score(X_val, y_val)\n",
    "test_score = our_mlp.score(X_test, y_test)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax1.plot(our_mlp.train_loss_curve, label=\"Training Loss\")\n",
    "ax1.plot(our_mlp.val_loss_curve, label=\"Validation Loss\")\n",
    "ax1.set_title(\"Loss over epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.bar([f\"Train: {training_score:.3f}\", f\"Val: {validation_score:.3f}\", f\"Test: {test_score:.3f}\"], \n",
    "    [training_score, validation_score, test_score])\n",
    "ax2.set_title(\"Accuracy on different sets\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylim(0,1)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = our_mlp.predict(X_test)\n",
    "cm = classification_report(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932bfcf",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03803e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "sklearn_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(50, 20),\n",
    "    activation=\"tanh\",\n",
    "    max_iter=25,\n",
    "    learning_rate_init=0.05,\n",
    "    learning_rate=\"constant\",\n",
    "    solver=\"sgd\",\n",
    "    batch_size=200,\n",
    "    nesterovs_momentum=False,\n",
    "    momentum=0,\n",
    "    alpha=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "sklearn_mlp = sklearn_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = sklearn_mlp.score(X_train, y_train)\n",
    "validation_score = sklearn_mlp.score(X_val, y_val)\n",
    "test_score = sklearn_mlp.score(X_test, y_test)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax1.plot(sklearn_mlp.loss_curve_)\n",
    "ax1.set_title(\"Loss over epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "ax2.bar([f\"Train: {training_score:.3f}\", f\"Val: {validation_score:.3f}\", f\"Test: {test_score:.3f}\"], \n",
    "    [training_score, validation_score, test_score])\n",
    "ax2.set_title(\"Accuracy on different sets\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylim(0,1)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = sklearn_mlp.predict(X_test)\n",
    "cm = classification_report(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fce156",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = sklearn_mlp.score(X_train, y_train)\n",
    "validation_score = sklearn_mlp.score(X_val, y_val)\n",
    "test_score = sklearn_mlp.score(X_test, y_test)\n",
    "plt.bar([f\"Train: {training_score:.3f}\", f\"Val: {validation_score:.3f}\", f\"Test: {test_score:.3f}\"], \n",
    "    [training_score, validation_score, test_score])\n",
    "plt.title(\"Accuracy on different sets\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Free GPU memory\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# clear tensoflow backend\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99260073",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_X_train = X_train.toarray()\n",
    "keras_X_val = X_val.toarray()\n",
    "keras_y_train = y_train - 1\n",
    "keras_y_val = y_val - 1\n",
    "model.fit(keras_X_train, keras_y_train, epochs=10, validation_data=(keras_X_val, keras_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08a055",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Lambda, Symbol\n",
    "from training import matrix_train\n",
    "\n",
    "\n",
    "x = Symbol(\"x\")\n",
    "\n",
    "\n",
    "# each axis must be an iterable. if you want to use a constant, wrap it in an iterable of len 1\n",
    "hyperparameter_matrix = {\n",
    "    \"epochs\": np.logspace(np.log10(100), np.log10(100000), num=20, dtype=\"int64\"),\n",
    "    \"lr\": np.logspace(np.log10(.00001), np.log10(.1), num=20),\n",
    "    \"hidden_layers\": [5, 6, 7],\n",
    "    \"neurons_per_layer\": [3],\n",
    "    \"activation\": [Lambda(x, x**2)],\n",
    "}\n",
    "\n",
    "best_params = matrix_train(hyperparameter_matrix, MultiLayerPerceptron, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(best_params)\n",
    "# mlp = MultiLayerPerceptron(**best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67082690",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ef1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import accuracy, confusion, report\n",
    "\n",
    "\n",
    "mlp = MultiLayerPerceptron(**best_params)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# print(accuracy(mlp.predict(X_test), y_test))\n",
    "# print(confusion(mlp.predict(X_test), y_test))\n",
    "print(report(mlp.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7f405",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO utilize other classifiers and compare performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3eb7f267467d6c03b504a34921e6add82dd5c3f67d72f72325143bde61c1eed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
