{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7b3dd5",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron\n",
    "\n",
    "The implementation of a multi-layer perceptron for the purposes of sentiment analysis. \n",
    "\n",
    "## Authors\n",
    "- Matthew Freestone\n",
    "- Will Humphlett\n",
    "- Matthew Shipplet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88acdd",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "Configures the notebook, assumes you are using the base conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.bootstrap import setup\n",
    "\n",
    "setup()\n",
    "    \n",
    "print(\"Notebook setup has completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4455f12",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Downloads configured dataset and performs necessary environment bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bootstrap import *\n",
    "\n",
    "# other datasets available in src.bootstrap\n",
    "DATASETS = [CDS_AND_VINYL_JSON_PARAMS, CELL_PHONE_JSON_PARAMS , KINDLE_STORE_JSON_PARAMS, SPORTS_JSON_PARAMS]\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    download_data_file(dataset['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de69ce6",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Sanitize data to prepare for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34451556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import get_dataframe\n",
    "\n",
    "df = get_dataframe(DATASETS, equalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbef2d4",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Convert the dataset into a usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f44ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from src.preprocessing import get_subsets\n",
    "\n",
    "word_vectorizer = CountVectorizer(\n",
    "    min_df=0.0001, \n",
    "    max_df=0.7\n",
    ")\n",
    "\n",
    "X = word_vectorizer.fit_transform(df[\"reviewText\"].to_numpy())\n",
    "\n",
    "# optional, convert a 5 class problem into a 3 class problem\n",
    "df['overall'].replace(2, 1, inplace=True)\n",
    "df['overall'].replace(4, 5, inplace=True)\n",
    "\n",
    "y = df['overall'].to_numpy()\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_subsets(X,y, train_split=0.8, val_split=0.1, test_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0711f",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Full implementation of our Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Sequence, Tuple\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered in exp\")\n",
    "\n",
    "\n",
    "def sigmoid(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Sigmoid function\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-X))\n",
    "\n",
    "\n",
    "def dSigmoid(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Derivative of sigmoid function\"\"\"\n",
    "    a = 1.0 / (1.0 + np.exp(-X))\n",
    "    return a * (1 - a)\n",
    "\n",
    "\n",
    "def tanh(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Tanh function\"\"\"\n",
    "    return np.tanh(X)\n",
    "\n",
    "\n",
    "def dTanh(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Derivative of tanh function\"\"\"\n",
    "    return 1.0 - np.tanh(X) ** 2\n",
    "\n",
    "\n",
    "def relu(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Rectified linear unit function\"\"\"\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "\n",
    "def dRelu(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Derivative of rectified linear unit function\"\"\"\n",
    "    return np.where(X > 0, 1, 0)\n",
    "\n",
    "\n",
    "def softmax(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Softmax\"\"\"\n",
    "    tmp = X - X.max(axis=1)[:, np.newaxis]\n",
    "    return np.exp(tmp) / np.exp(tmp).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def squared_loss(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"Mean squared loss\"\"\"\n",
    "    return ((y_true - y_pred) ** 2).mean() / 2\n",
    "\n",
    "\n",
    "def L1_reg_loss(weights: List[np.ndarray]) -> float:\n",
    "    \"\"\"Lasso regression\"\"\"\n",
    "    c = 0\n",
    "    for w in weights:\n",
    "        c += np.sum(np.abs(w))\n",
    "    return c\n",
    "\n",
    "\n",
    "def L1_reg_grad(weights: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"Lasso regression grad\"\"\"\n",
    "    grad = []\n",
    "    for w in weights:\n",
    "        grad.append(np.where(w > 0, 1, -1))\n",
    "    return grad\n",
    "\n",
    "\n",
    "def L2_reg_loss(weights: List[np.ndarray]) -> float:\n",
    "    \"\"\"Ridge regression\"\"\"\n",
    "    c = 0\n",
    "    for w in weights:\n",
    "        w = w.ravel()\n",
    "        c += np.dot(w, w)\n",
    "    return c\n",
    "\n",
    "\n",
    "def L2_reg_grad(weights: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"Ridge regression grad\"\"\"\n",
    "    return [2 * w for w in weights]\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        lr: float,\n",
    "        hidden_layers: Sequence[int],\n",
    "        regularization: str = None,\n",
    "        reg_const: float = 0.0,\n",
    "        activation: str = \"sigmoid\",\n",
    "    ):\n",
    "        \"\"\"An implementation of a multi-layer perceptron with backpropagation\n",
    "\n",
    "        :param epochs: Number of epochs\n",
    "        :param lr: Learning rate\n",
    "        :param hidden_layers: Sequence of integers representing the number of neurons in each hidden layer\n",
    "        :param regularization: Regularization function, [\"l1\", \"l2\"]\n",
    "        :param reg_const: Regularization constant\n",
    "        :param activation: Activation function, [\"sigmoid\", \"tanh\", \"relu\"], default=\"sigmoid\"\n",
    "        \"\"\"\n",
    "        self.num_epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.reg_const = reg_const\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_layer = None\n",
    "        self.input_layer = None\n",
    "        self._num_layers = len(self.hidden_layers) + 2\n",
    "        self._yencoder = LabelBinarizer()\n",
    "\n",
    "        self._output_activation = None\n",
    "\n",
    "        if activation == \"sigmoid\" or activation == \"logistic\":\n",
    "            self.activation = sigmoid\n",
    "            self.dActivation = dSigmoid\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = tanh\n",
    "            self.dActivation = dTanh\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = relu\n",
    "            self.dActivation = dRelu\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "        if regularization is None:\n",
    "            pass\n",
    "        elif regularization.lower() == \"l1\":\n",
    "            self._loss_reg = L1_reg_loss\n",
    "            self._grad_reg = L1_reg_grad\n",
    "        elif regularization.lower() == \"l2\":\n",
    "            self._loss_reg = L2_reg_loss\n",
    "            self._grad_reg = L2_reg_grad\n",
    "        else:\n",
    "            raise ValueError(\"Invalid regularization function\")\n",
    "\n",
    "        self._loss_function = squared_loss\n",
    "        self._biases = None\n",
    "        self._weights = None\n",
    "        self.train_loss_curve = []\n",
    "        self.val_loss_curve = []\n",
    "\n",
    "    def epochs(self):\n",
    "        for i in range(self.num_epochs):\n",
    "            yield i, self.lr\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        X_val: np.ndarray = None,\n",
    "        y_val: np.ndarray = None,\n",
    "        batch_size: int = 1,\n",
    "        continue_fit=False,\n",
    "        output=True,\n",
    "    ) -> None:\n",
    "        \"\"\"Fits the model to given data\n",
    "\n",
    "        :param X: Input data of shape (n_examples, n_features)\n",
    "        :param y: Output data of shape (n_examples, )\n",
    "        :param X_val: Validation input data of shape (n_examples, n_features)\n",
    "        :param y_val: Validation output data of shape (n_examples, )\n",
    "        :param batch_size: Size of the batch to be used for training, default=1\n",
    "        :param continue_fit: Continue training from last epoch, default=False\n",
    "        :param output: Display a progress bar of model fitting, default=True\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if len(X.shape) != 2:\n",
    "            raise ValueError(\"Invalid shape for X\")\n",
    "        if len(y.shape) != 1:\n",
    "            raise ValueError(\"Invalid shape for y\")\n",
    "        n_examples, n_features = X.shape\n",
    "\n",
    "        use_val = False\n",
    "        if X_val is not None and y_val is not None:\n",
    "            use_val = True\n",
    "            if len(X_val.shape) != 2:\n",
    "                raise ValueError(\"Invalid shape for X_val\")\n",
    "            if len(y_val.shape) != 1:\n",
    "                raise ValueError(\"Invalid shape for y_val\")\n",
    "        y_combined = np.concatenate((y, y_val)) if use_val else y\n",
    "        y_combined = self._format_labels(y_combined)\n",
    "        y, y_val = np.split(y_combined, [n_examples]) if use_val else (y_combined, None)\n",
    "\n",
    "        if not continue_fit:\n",
    "            self.input_layer = n_features\n",
    "            self.output_layer = y.shape[1]\n",
    "            self._structure = (self.input_layer, *self.hidden_layers, self.output_layer)\n",
    "\n",
    "            self._biases = [np.random.randn(y, 1) for y in self._structure[1:]]\n",
    "            self._weights = [np.random.randn(x, y) for x, y in zip(self._structure[:-1], self._structure[1:])]\n",
    "\n",
    "        epochs = tqdm(self.epochs(), total=self.num_epochs) if output else self.epochs()\n",
    "\n",
    "        for epoch_num, lr in epochs:\n",
    "            train_loss = 0\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[i : i + batch_size]\n",
    "                y_batch = y[i : i + batch_size]\n",
    "                dJdB, dJdW, c_loss = self._backprop(X_batch, y_batch)\n",
    "                train_loss += c_loss\n",
    "\n",
    "                self._biases = [b - lr * db for b, db in zip(self._biases, dJdB)]\n",
    "                self._weights = [w - lr * dw for w, dw in zip(self._weights, dJdW)]\n",
    "            num_batches = X.shape[0] // batch_size\n",
    "            self.train_loss_curve.append(train_loss / num_batches)\n",
    "            if use_val:\n",
    "                val_loss = self._calc_loss(y_val, self._fast_forward_pass(X_val))\n",
    "                self.val_loss_curve.append(val_loss)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predicts the output for the given input\n",
    "\n",
    "        :param X: Input data of shape (n_examples, n_features)\n",
    "        :return: Output data of shape (n_examples, )\n",
    "        \"\"\"\n",
    "        curr = self._fast_forward_pass(X)\n",
    "        if self.output_layer == 1:\n",
    "            curr = curr.ravel()\n",
    "        return self._yencoder.inverse_transform(curr)\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Returns the accuracy of the model on the given data\n",
    "\n",
    "        :param X: Input data of shape (n_examples, n_features)\n",
    "        :param y: Output data of shape (n_examples, )\n",
    "        :return: Accuracy score\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def plot_loss(self) -> None:\n",
    "        \"\"\"The loss over epochs plot\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        plt.plot(self.train_loss_curve, label=\"Training loss\")\n",
    "        if self.val_loss_curve and len(self.val_loss_curve) == len(self.train_loss_curve):\n",
    "            plt.plot(self.val_loss_curve, label=\"Validation loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss vs Epoch\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _format_labels(self, y: np.ndarray) -> np.ndarray:\n",
    "        if len(y.shape) == 2 and y.shape[1] == 1:\n",
    "            y = y.ravel()\n",
    "        elif len(y.shape) == 2 and y.shape[1] > 1 or len(y.shape) > 2:\n",
    "            raise ValueError(\"Invalid shape for y\")\n",
    "\n",
    "        self._yencoder.fit(y)\n",
    "        if len(self._yencoder.classes_) == 2:\n",
    "            self._output_activation = sigmoid\n",
    "        else:\n",
    "            self._output_activation = softmax\n",
    "        return self._yencoder.transform(y)\n",
    "\n",
    "    def _backprop(self, X: np.ndarray, y: np.ndarray) -> Tuple[List[np.ndarray], List[np.ndarray], float]:\n",
    "        # initialize empty lists to store the gradient of the biases and weights\n",
    "        dBias = [np.zeros(b.shape) for b in self._biases]\n",
    "        dWeights = [np.zeros(w.shape) for w in self._weights]\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # do a forward pass to get the activations and z values\n",
    "        layer_raw = []  # stores the weighted sum of inputs for each layer\n",
    "        layer_activations = []  # stores the output of each layer\n",
    "        a = X  # input layer\n",
    "        for i, (b, W) in enumerate(zip(self._biases, self._weights)):\n",
    "            # compute the weighted sum of inputs for this layer\n",
    "            z = a @ W + b.T\n",
    "\n",
    "            # apply the activation function to the output of this layer\n",
    "            if i < self._num_layers - 2:\n",
    "                a = self.activation(z)\n",
    "            else:\n",
    "                a = self._output_activation(z)\n",
    "            # store the raw output and the activated output of this layer\n",
    "            layer_raw.append(z)\n",
    "            layer_activations.append(a)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = self._calc_loss(y, a)\n",
    "\n",
    "        # index of the last hidden layer\n",
    "        last_hidden = self._num_layers - 2\n",
    "\n",
    "        # compute the error at the last hidden layer\n",
    "        delta = layer_activations[last_hidden] - y\n",
    "\n",
    "        # compute the gradient of the biases and weights for the last hidden layer\n",
    "        dBias[last_hidden] = np.mean(delta, axis=0)\n",
    "        dWeights[last_hidden] = layer_activations[last_hidden - 1].T @ delta\n",
    "\n",
    "        # for all hidden layers except the first and last,\n",
    "        # compute the gradient of the biases and weights\n",
    "        for L in range(last_hidden - 1, 0, -1):\n",
    "            # compute the error at this layer\n",
    "            delta = (delta @ self._weights[L + 1].T) * self.dActivation(layer_raw[L])\n",
    "\n",
    "            # compute the gradient of the biases and weights for this layer\n",
    "            dBias[L] = np.mean(delta, axis=0)\n",
    "            dWeights[L] = layer_activations[L - 1].T @ delta\n",
    "\n",
    "        # for the input layer, compute the gradient of the biases and weights\n",
    "        # using the inputs, rather than the previous layer\n",
    "        delta = (delta @ self._weights[1].T) * self.dActivation(layer_raw[0])\n",
    "        dBias[0] = np.mean(delta, axis=0)\n",
    "        dWeights[0] = X.T @ delta\n",
    "\n",
    "        # add a second dimension to the bias gradient to make it compatible with the bias shape\n",
    "        dBias = [db[:, np.newaxis] for db in dBias]\n",
    "        # divide by number of samples to get the average gradient\n",
    "        dWeights = [dw / n_samples for dw in dWeights]\n",
    "\n",
    "        # apply regularization if enabled\n",
    "        if self.regularization:\n",
    "            dWeights = [dw + self.reg_const * r for dw, r in zip(dWeights, self._grad_reg(self._weights))]\n",
    "        return dBias, dWeights, loss\n",
    "\n",
    "    def _calc_loss(self, y_pred: np.ndarray, y_batch: np.ndarray) -> float:\n",
    "        loss = self._loss_function(y_pred, y_batch)\n",
    "        if self.regularization:\n",
    "            loss += (0.5 * self.reg_const) * self._loss_reg(self._weights) / y_pred.shape[0]\n",
    "        return loss\n",
    "\n",
    "    def _fast_forward_pass(self, X: np.ndarray) -> np.ndarray:\n",
    "        curr = X\n",
    "        for i in range(self._num_layers - 1):\n",
    "            curr = curr @ self._weights[i]\n",
    "            curr += self._biases[i].T\n",
    "            if i < self._num_layers - 2:\n",
    "                curr = self.activation(curr)\n",
    "            else:\n",
    "                curr = self._output_activation(curr)\n",
    "        return curr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe832a0e",
   "metadata": {},
   "source": [
    "## Two Dimension Problem\n",
    "Prove that our implemenation of an MLP can learn non-linear decision planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.two_dim_problem import TwoDimProblem\n",
    "\n",
    "problem = TwoDimProblem(5)\n",
    "X, y = problem.create_data(2, 0.05, 500)\n",
    "problem.plot_data(show_seperator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1588a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultiLayerPerceptron(epochs=50, lr=0.2, hidden_layers=(10, 5))\n",
    "mlp.fit(X, y)\n",
    "problem.plot_pred(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5e96b",
   "metadata": {},
   "source": [
    "## Training\n",
    "Determine optimal hyperparamters given our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c81192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import matrix_train\n",
    "\n",
    "# each axis must be an iterable. if you want to use a constant, wrap it in an iterable of len 1\n",
    "hyperparameter_matrix = {\n",
    "    \"epochs\": np.logspace(np.log10(10), np.log10(100), num=5, dtype=\"int64\"),\n",
    "    \"lr\": np.logspace(np.log10(.00002), np.log10(.2), num=5),\n",
    "    \"hidden_layers\": [[50, 20]],\n",
    "    \"activation\": [\"sigmoid\", \"tanh\", \"relu\"],\n",
    "    \"regularization\": [\"L2\", \"L1\"],\n",
    "    \"reg_const\": [0.0001, 0.001],\n",
    "}\n",
    "\n",
    "# look at data/train.log for progress\n",
    "\n",
    "best_params = matrix_train(hyperparameter_matrix, MultiLayerPerceptron, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(best_params)\n",
    "# mlp = MultiLayerPerceptron(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved for convenience\n",
    "best_params = {\n",
    "    \"epochs\": 20, \"lr\": .2, \"hidden_layers\": [50, 20], \"activation\": \"sigmoid\", \"regularization\": \"L2\", \"reg_const\": .0001\n",
    "}\n",
    "\n",
    "mlp = MultiLayerPerceptron(**best_params)\n",
    "mlp.fit(X_train, y_train, X_val, y_val, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7486d",
   "metadata": {},
   "source": [
    "## Performance\n",
    "Detailed performance report of our mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis import accuracy, confusion, report, plots\n",
    "\n",
    "print(report(mlp.predict(X_test), y_test))\n",
    "\n",
    "plots(mlp.score(X_train, y_train), mlp.score(X_test, y_test), mlp.score(X_val, y_val), mlp.train_loss_curve, mlp.val_loss_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112831b",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3ad38",
   "metadata": {},
   "source": [
    "### SKLearn Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "skl_mlp = MLPClassifier(\n",
    "    early_stopping=True,\n",
    ")\n",
    "skl_mlp = skl_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc540728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report(skl_mlp.predict(X_test), y_test))\n",
    "\n",
    "plots(skl_mlp.score(X_train, y_train), skl_mlp.score(X_test, y_test), skl_mlp.score(X_val, y_val), skl_mlp.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce3ed9",
   "metadata": {},
   "source": [
    "### SKLearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef60d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report(rf.predict(X_test), y_test))\n",
    "\n",
    "plots(rf.score(X_train, y_train), rf.score(X_test, y_test), rf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8c47d",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8696c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# clear tensoflow backend\n",
    "tf.keras.backend.clear_session()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "tf_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "tf_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\", \"mse\", \"mae\"]\n",
    ")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd512c",
   "metadata": {},
   "source": [
    "Tensorflow does not accept data in the sparse representation, we must convert it to a dense representation. We also need to convert the labels to one-hot encoding.\n",
    "However, the dataset is too large to fit in memory as a dense representation, so we will only use a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a3f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 16527) (24000, 3)\n",
      "(3000, 16527) (3000, 3)\n",
      "(3000, 16527) (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "SIZE = 10_000\n",
    "TRAIN_SIZE_RATIO = 0.8\n",
    "VAL_SIZE_RATIO = 0.1\n",
    "TEST_SIZE_RATIO = 0.1\n",
    "\n",
    "keras_y_encoder = LabelBinarizer()\n",
    "\n",
    "keras_X_train = np.concatenate((X_train[y_train == 1][:int(SIZE*TRAIN_SIZE_RATIO)].toarray(), X_train[y_train == 3][:int(SIZE*TRAIN_SIZE_RATIO)].toarray(), X_train[y_train == 5][:int(SIZE*TRAIN_SIZE_RATIO)].toarray()))\n",
    "keras_y_train = np.concatenate((y_train[y_train == 1][:int(SIZE*TRAIN_SIZE_RATIO)], y_train[y_train == 3][:int(SIZE*TRAIN_SIZE_RATIO)], y_train[y_train == 5][:int(SIZE*TRAIN_SIZE_RATIO)]))\n",
    "keras_y_train = keras_y_encoder.fit_transform(keras_y_train)\n",
    "\n",
    "\n",
    "keras_X_val = np.concatenate((X_val[y_val == 1][:int(SIZE*VAL_SIZE_RATIO)].toarray(), X_val[y_val == 3][:int(SIZE*VAL_SIZE_RATIO)].toarray(), X_val[y_val == 5][:int(SIZE*VAL_SIZE_RATIO)].toarray()))\n",
    "keras_y_val = np.concatenate((y_val[y_val == 1][:int(SIZE*VAL_SIZE_RATIO)], y_val[y_val == 3][:int(SIZE*VAL_SIZE_RATIO)], y_val[y_val == 5][:int(SIZE*VAL_SIZE_RATIO)]))\n",
    "keras_y_val = keras_y_encoder.transform(keras_y_val)\n",
    "\n",
    "keras_X_test = np.concatenate((X_test[y_test == 1][:int(SIZE*TEST_SIZE_RATIO)].toarray(), X_test[y_test == 3][:int(SIZE*TEST_SIZE_RATIO)].toarray(), X_test[y_test == 5][:int(SIZE*TEST_SIZE_RATIO)].toarray()))\n",
    "keras_y_test = np.concatenate((y_test[y_test == 1][:int(SIZE*TEST_SIZE_RATIO)], y_test[y_test == 3][:int(SIZE*TEST_SIZE_RATIO)], y_test[y_test == 5][:int(SIZE*TEST_SIZE_RATIO)]))\n",
    "keras_y_test = keras_y_encoder.transform(keras_y_test)\n",
    "\n",
    "print(keras_X_train.shape, keras_y_train.shape)\n",
    "print(keras_X_val.shape, keras_y_val.shape)\n",
    "print(keras_X_test.shape, keras_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a05966ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.8639 - accuracy: 0.6042 - mse: 0.1709 - mae: 0.3476 - val_loss: 0.7693 - val_accuracy: 0.6560 - val_mse: 0.1525 - val_mae: 0.3013\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5992 - accuracy: 0.7480 - mse: 0.1171 - mae: 0.2408 - val_loss: 0.8309 - val_accuracy: 0.6250 - val_mse: 0.1629 - val_mae: 0.2932\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4083 - accuracy: 0.8363 - mse: 0.0783 - mae: 0.1672 - val_loss: 0.9918 - val_accuracy: 0.6303 - val_mse: 0.1755 - val_mae: 0.2808\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2730 - accuracy: 0.8991 - mse: 0.0500 - mae: 0.1109 - val_loss: 1.2306 - val_accuracy: 0.6197 - val_mse: 0.1892 - val_mae: 0.2747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1562876a400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.fit(keras_X_train, keras_y_train, epochs=10, validation_data=(keras_X_val, keras_y_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a2087af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 5, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y_encoder.inverse_transform(tf_model.predict(keras_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a5a5585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 3ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.65685   0.64700   0.65189      1000\n",
      "           3    0.50938   0.48900   0.49898      1000\n",
      "           5    0.66730   0.70400   0.68516      1000\n",
      "\n",
      "    accuracy                        0.61333      3000\n",
      "   macro avg    0.61118   0.61333   0.61201      3000\n",
      "weighted avg    0.61118   0.61333   0.61201      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = keras_y_encoder.inverse_transform(tf_model.predict(keras_X_train))\n",
    "y_train_true = keras_y_encoder.inverse_transform(keras_y_train)\n",
    "\n",
    "y_val_pred = keras_y_encoder.inverse_transform(tf_model.predict(keras_X_val))\n",
    "y_val_true = keras_y_encoder.inverse_transform(keras_y_val)\n",
    "\n",
    "y_test_pred = keras_y_encoder.inverse_transform(tf_model.predict(keras_X_test))\n",
    "y_test_true = keras_y_encoder.inverse_transform(keras_y_test)\n",
    "\n",
    "print(report(y_test_pred, y_test_true))\n",
    "plots(accuracy(y_train_pred, y_train_true), accuracy(y_test_pred, y_test_true), accuracy(y_val_pred, y_val_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8607d81fc6318cb05ed35a8010608a8fe3010a47ba3e0e927835a55241641039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
